{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Import needed libraries","metadata":{}},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom glob import glob\n#---------------------------------------\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n#---------------------------------------\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.metrics import Precision, Recall\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n#---------------------------------------\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_rows, img_cols = 128, 128\ninput_shape = (img_rows, img_cols, 3)\n\n#n_classes = df['category'].nunique()\nn_classes = 4\nprint('Total number of unique categories:', n_classes)\n\nfrom os import listdir, makedirs\nfrom os.path import isfile, join, basename, splitext, isfile, exists\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm_notebook\n\nimport tensorflow as tf\nimport keras.backend as K\n\nimport keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dropout, Dense, Flatten, BatchNormalization\nfrom keras.layers import DepthwiseConv2D, SeparableConvolution2D, Convolution2D, Conv2D,GRU, LSTM, AlphaDropout, Embedding, ZeroPadding2D,AveragePooling2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D, Dropout\nfrom keras.layers import Concatenate, Average, Maximum, Bidirectional, TimeDistributed\nfrom keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n#from keras.engine.input_layer import Input\nfrom keras.models import load_model\n#from keras.initializers import LecunNormal\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#pd.set_option('precision', 30)\nnp.set_printoptions(precision = 30)\n\n\n#tf.set_random_seed(1090)\n\nimport pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\n\nimport cv2\nimport itertools\nimport pathlib\nimport warnings\nfrom PIL import Image\nfrom random import randint\nwarnings.filterwarnings('ignore')\n\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import matthews_corrcoef as MCC\nfrom sklearn.metrics import balanced_accuracy_score as BAS\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n\nfrom tensorflow import keras\nfrom keras import layers\nimport tensorflow as tf\n#import tensorflow_addons as tfa\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n##from keras.utils.vis_utils import plot_model\nfrom tensorflow.keras import Sequential, Input\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.layers import Conv2D, Flatten\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG\nfrom tensorflow.keras.layers import SeparableConv2D, BatchNormalization, GlobalAveragePooling2D\n\nfrom distutils.dir_util import copy_tree, remove_tree\n\nimport os\n#print(os.listdir(\"../input/alzheimer-mri-dataset/Dataset\"))\nimport tensorflow as tf\nfrom keras.datasets import mnist\nimport cv2\nimport os\nimport pathlib\nfrom keras.layers import Conv2D, Conv2DTranspose,Concatenate, Dropout, Dense, Reshape, LayerNormalization, LeakyReLU\nfrom keras import layers, models\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.metrics import f1_score, recall_score, precision_score\nprint(\"TensorFlow Version:\", tf.__version__)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Uncertainty Quantification of DRIFA-Net","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.losses import KLDivergence\n\n# Set a random seed for reproducibility\nnp.random.seed(42)\n\ndef create_ensemble(num_models, input_shape=(128, 128, 3)):\n    ensemble_models = []\n    \n    for _ in range(num_models):\n        model = DRIFA_Net(input_shape)  # Assuming ResNet18 is defined elsewhere\n        ensemble_models.append(model)\n    \n    return ensemble_models\n\n# Function to perform Monte Carlo Dropout inference\n\n# Example usage\ninput_shape = (128, 128, 3)\nnum_models = 5\ndropout_rate = 0.25\n\nensemble_models = create_ensemble(num_models, input_shape)\n\n# Train each model in the ensemble\nfor i, model in enumerate(ensemble_models):\n    print(\"Training Model\", i)\n    #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    model.compile(optimizer='adam', loss=[adaptive_knowledge_distillation_loss,\n                                              adaptive_knowledge_distillation_loss,\n                                             adaptive_knowledge_distillation_loss,\n                                             adaptive_knowledge_distillation_loss], \n                      metrics=['accuracy', 'accuracy', 'accuracy', 'accuracy'])\n\n    \n    # Define checkpoint callback for each model\n    checkpoint = ModelCheckpoint(f\"best_student_models1_covid_brain_{i}.keras\", monitor='val_loss', \n                                 verbose=1, save_best_only=True, mode='min')\n    \n    model.fit(x = [images_train_brain_mri, images_train_brain_ct, images_train_covid_cxr,  images_train_covid_ct], \n    y=([soft_prob_brain_mri, soft_prob_brain_ct, soft_prob_covid_cxr, soft_prob_covid_ct]),\n    epochs=200,\n    #validation_data=([X_val, X_val_c], [y_val, y_val_c]), \n    callbacks = [checkpoint],#batch_size=16,\n    #validation_split = 0.2\n    validation_data = ([X_val_brain_mri, X_val_brain_ct, X_val_covid_cxr, X_val_covid_ct],\n                      [y_val_brain_mri, y_val_brain_ct, y_val_covid_cxr, y_val_covid_ct]), verbose=0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i, model in enumerate(ensemble_models):\n    model.evaluate([X_test_brain_mri, X_test_brain_ct,X_test_covid_cxr, X_test_covid_ct], \n[y_test_brain_mri,y_test_brain_ct, y_test_covid_cxr, y_test_covid_ct])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''def monte_carlo_dropout_inference(model, x1, x2, x3, x4, num_samples=3):\n    predictions = np.zeros((num_samples,) + model.predict([x1, x2, x3, x4],\n                                                          verbose = 0).shape)\n    print(len(predictions))\n    \n    for i in range(num_samples):\n        print(i)\n        predictions[i, :] = model.predict([x1, x2, x3, x4], verbose = 0)\n\n    return predictions\n'''\n\ndef monte_carlo_dropout_inference(model, x1, x2, x3, x4, num_samples=30):\n    predictions_shape = model.predict([x1, x2, x3, x4], verbose=0)[0].shape\n    predictions = np.zeros((num_samples,) + predictions_shape)\n    \n    for i in range(num_samples):\n        predictions[i, :] = model.predict([x1, x2, x3, x4], verbose=0)[0]\n\n    return predictions\n# Perform Monte Carlo Dropout inference for each model in the ensemble\nensemble_predictions = []\nfor model in ensemble_models:\n    predictions = monte_carlo_dropout_inference(model, X_test_brain_mri, \n                                                        X_test_brain_ct,X_test_covid_cxr, X_test_covid_ct)\n    ensemble_predictions.append(predictions)\n\n#print('ensemble_predictions:', ensemble_predictions.shape)\n# Take the mean or other aggregation method across the ensemble predictions\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_prediction_model1 = np.mean(ensemble_predictions[0], axis=0)\n\n# Use the final_prediction for further analysis or decision making\nprint(\"final_prediction_model1:\", final_prediction_model1.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''def monte_carlo_dropout_inference(model, x1, x2, x3, x4, num_samples=3):\n    predictions = np.zeros((num_samples,) + model.predict([x1, x2, x3, x4],\n                                                          verbose = 0).shape)\n    print(len(predictions))\n    \n    for i in range(num_samples):\n        print(i)\n        predictions[i, :] = model.predict([x1, x2, x3, x4], verbose = 0)\n\n    return predictions\n'''\n\ndef monte_carlo_dropout_inference(model, x1, x2, x3, x4, num_samples=30):\n    predictions_shape = model.predict([x1, x2, x3, x4], verbose=0)[1].shape\n    predictions = np.zeros((num_samples,) + predictions_shape)\n    \n    for i in range(num_samples):\n        predictions[i, :] = model.predict([x1, x2, x3, x4], verbose=0)[1]\n\n    return predictions\n# Perform Monte Carlo Dropout inference for each model in the ensemble\nensemble_predictions = []\nfor model in ensemble_models:\n    predictions = monte_carlo_dropout_inference(model, X_test_brain_mri, \n                                                        X_test_brain_ct,X_test_covid_cxr, X_test_covid_ct)\n    ensemble_predictions.append(predictions)\n\n#print('ensemble_predictions:', ensemble_predictions.shape)\n# Take the mean or other aggregation method across the ensemble predictions\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_prediction_model2 = np.mean(ensemble_predictions[0], axis=0)\n\n# Use the final_prediction for further analysis or decision making\nprint(\"final_prediction_model2:\", final_prediction_model2.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''def monte_carlo_dropout_inference(model, x1, x2, x3, x4, num_samples=3):\n    predictions = np.zeros((num_samples,) + model.predict([x1, x2, x3, x4],\n                                                          verbose = 0).shape)\n    print(len(predictions))\n    \n    for i in range(num_samples):\n        print(i)\n        predictions[i, :] = model.predict([x1, x2, x3, x4], verbose = 0)\n\n    return predictions\n'''\n\ndef monte_carlo_dropout_inference(model, x1, x2, x3, x4, num_samples=30):\n    predictions_shape = model.predict([x1, x2, x3, x4], verbose=0)[2].shape\n    predictions = np.zeros((num_samples,) + predictions_shape)\n    \n    for i in range(num_samples):\n        predictions[i, :] = model.predict([x1, x2, x3, x4], verbose=0)[2]\n\n    return predictions\n# Perform Monte Carlo Dropout inference for each model in the ensemble\nensemble_predictions = []\nfor model in ensemble_models:\n    predictions = monte_carlo_dropout_inference(model, X_test_brain_mri, \n                                                        X_test_brain_ct,X_test_covid_cxr, X_test_covid_ct)\n    ensemble_predictions.append(predictions)\n\n#print('ensemble_predictions:', ensemble_predictions.shape)\n# Take the mean or other aggregation method across the ensemble predictions\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_prediction_model3 = np.mean(ensemble_predictions[0], axis=0)\n\n# Use the final_prediction for further analysis or decision making\nprint(\"final_prediction_model3:\", final_prediction_model3.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''def monte_carlo_dropout_inference(model, x1, x2, x3, x4, num_samples=3):\n    predictions = np.zeros((num_samples,) + model.predict([x1, x2, x3, x4],\n                                                          verbose = 0).shape)\n    print(len(predictions))\n    \n    for i in range(num_samples):\n        print(i)\n        predictions[i, :] = model.predict([x1, x2, x3, x4], verbose = 0)\n\n    return predictions\n'''\n\ndef monte_carlo_dropout_inference(model, x1, x2, x3, x4, num_samples=30):\n    predictions_shape = model.predict([x1, x2, x3, x4], verbose=0)[3].shape\n    predictions = np.zeros((num_samples,) + predictions_shape)\n    \n    for i in range(num_samples):\n        predictions[i, :] = model.predict([x1, x2, x3, x4], verbose=0)[3]\n\n    return predictions\n# Perform Monte Carlo Dropout inference for each model in the ensemble\nensemble_predictions = []\nfor model in ensemble_models:\n    predictions = monte_carlo_dropout_inference(model, X_test_brain_mri, \n                                                        X_test_brain_ct,X_test_covid_cxr, X_test_covid_ct)\n    ensemble_predictions.append(predictions)\n\n#print('ensemble_predictions:', ensemble_predictions.shape)\n# Take the mean or other aggregation method across the ensemble predictions\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_prediction_model4 = np.mean(ensemble_predictions[0], axis=0)\n\n# Use the final_prediction for further analysis or decision making\nprint(\"final_prediction_model4:\", final_prediction_model4.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred_binary_pgd_test1 = np.argmax(final_prediction_model1, axis=1)\ny_pred_binary_pgd_test2 = np.argmax(final_prediction_model2, axis=1)\ny_pred_binary_pgd_test3 = np.argmax(final_prediction_model3, axis=1)\ny_pred_binary_pgd_test4 = np.argmax(final_prediction_model4, axis=1)\n\ny_test_categorical1 = y_test_brain_mri\ny_test_categorical2 = y_test_brain_ct\ny_test_categorical4 = y_test_covid_ct\ny_test_categorical3 = y_test_covid_cxr\n\ny_test_categorical1 = np.argmax(y_test_categorical1, axis=1)\ny_test_categorical2 = np.argmax(y_test_categorical2, axis=1)\ny_test_categorical3 = np.argmax(y_test_categorical3, axis=1)\ny_test_categorical4 = np.argmax(y_test_categorical4, axis=1)\n\n## Task 1:\nprint('Task 1:')\nprint('Brain Tumours classification in MRI images:')\naccuracy = accuracy_score(y_pred_binary_pgd_test1, y_test_categorical1) * 100\nprecision = precision_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\n#auc = roc_auc_score(y_pred, y_train_categorical, multi_class='ovr') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)\n\n## Task 2:\nprint('Task 2:')\nprint('Brain Stroke classification in CT scan images:')\naccuracy = accuracy_score(y_pred_binary_pgd_test2, y_test_categorical2) * 100\nprecision = precision_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)\n\n## Task 3:\nprint('Task 3:')\nprint('COVID19 classification in CXR images:')\naccuracy = accuracy_score(y_pred_binary_pgd_test3, y_test_categorical3) * 100\nprecision = precision_score(y_pred_binary_pgd_test3, y_test_categorical3, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test3, y_test_categorical3, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test3, y_test_categorical3, average='macro') * 100\n#auc = roc_auc_score(y_pred, y_train_categorical, multi_class='ovr') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)\n\n## Task 4:\nprint('Task 4:')\nprint('COVID19 classification in CT scan images:')\naccuracy = accuracy_score(y_pred_binary_pgd_test4, y_test_categorical4) * 100\nprecision = precision_score(y_pred_binary_pgd_test4, y_test_categorical4, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test4, y_test_categorical4, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test4, y_test_categorical4, average='macro') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}