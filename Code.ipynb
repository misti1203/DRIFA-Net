{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1079953,"sourceType":"datasetVersion","datasetId":601280},{"sourceId":7957702,"sourceType":"datasetVersion","datasetId":4680825},{"sourceId":8031909,"sourceType":"datasetVersion","datasetId":4734294}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nsns.set_style('whitegrid')\nfrom sklearn.metrics import confusion_matrix , classification_report\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense , Flatten , Conv2D , MaxPooling2D , Dropout , Activation , BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam , Adamax\nfrom tensorflow.keras import regularizers\n\n#Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\ntf.keras.mixed_precision.set_global_policy('mixed_float16')\n\nimport tensorflow as tf\nimport numpy as np\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, ReLU, Add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import KLDivergence\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications import DenseNet121, ResNet50V2\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nimport copy\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, ReLU, Add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import KLDivergence\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications import DenseNet169, MobileNetV2, ResNet50, EfficientNetB0\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nimport copy\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_h = np.load('X_train_HAM10000_ISIC_2018.npy')\ny_train_h = np.load('y_train_HAM10000_ISIC_2018.npy')\nX_test_h = np.load('X_test_HAM10000_ISIC_2018.npy')\ny_test_h = np.load('y_test_HAM10000_ISIC_2018.npy')\n\n\nX_train_h.shape, y_train_h.shape, X_test_h.shape, y_test_h.shape\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"random_indices = np.random.choice(2003, 810, replace=False)\n\nX_test_h1 = X_test_h[random_indices]\ny_test_h1 = y_test_h[random_indices]\n\nX_test_h1.shape, y_test_h1.shape, X_test_h.shape, y_test_h.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#X_train_s.shape,X_test_s.shape, y_train_s.shape,y_test_s.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_h.shape, y_train_h.shape, X_test_h.shape, y_test_h.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_s = np.load('/kaggle/input/spikamed-ds/data_cervical_cancer_sipkamed.npy')\ny_train_s = np.load('/kaggle/input/spikamed-ds/labels_cervical_cancer_sipkamed.npy')\n\nX_train_s.shape, y_train_s.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_train_s, y_train_s, test_size=0.2, random_state=42)\n\nX_train_s.shape,X_test_s.shape, y_train_s.shape,y_test_s.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport cv2\n\ndef rotate_image(image, angle):\n    \"\"\"\n    Rotate the image by the specified angle.\n    \"\"\"\n    center = tuple(np.array(image.shape[1::-1]) / 2)\n    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n    rotated_image = cv2.warpAffine(image, rotation_matrix, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n    return rotated_image\n\ndef translate_image(image, tx, ty):\n    \"\"\"\n    Translate the image by the specified translation parameters.\n    \"\"\"\n    translation_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\n    translated_image = cv2.warpAffine(image, translation_matrix, image.shape[1::-1])\n    return translated_image\n\n# Example data\n#X_train = np.random.rand(100, 28, 28)  # Assuming 100 images of size 28x28\n#y_train = np.random.randint(0, 10, 100)  # Assuming 100 labels\n\n# Augmentation parameters\nrotation_angles = [20]\ntranslations = [(5, 5)]\n\naugmented_X_train = []\naugmented_y_train = []\n\nfor image, label in zip(X_train_s, y_train_s):\n    # Original image\n    #augmented_X_train.append(image)\n    #augmented_y_train.append(label)\n\n    # Augment with rotations\n    for angle in rotation_angles:\n        rotated_image = rotate_image(image, angle)\n        augmented_X_train.append(rotated_image)\n        augmented_y_train.append(label)\n\n    # Augment with translations\n    for tx, ty in translations:\n        translated_image = translate_image(image, tx, ty)\n        augmented_X_train.append(translated_image)\n        augmented_y_train.append(label)\n\n# Convert lists to numpy arrays\naugmented_X_train = np.array(augmented_X_train)\naugmented_y_train = np.array(augmented_y_train)\n\n# Shuffle the data\nshuffle_indices = np.random.permutation(len(augmented_X_train))\naugmented_X_train = augmented_X_train[shuffle_indices]\naugmented_y_train = augmented_y_train[shuffle_indices]\naugmented_X_train.shape, augmented_y_train.shape\n# Now, augmented_X_train and augmented_y_train contain the augmented dataset.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"random_indices = np.random.choice(6478, 4773, replace=False)\n\naugmented_X_train = augmented_X_train[random_indices]\naugmented_y_train = augmented_y_train[random_indices]\n\naugmented_X_train.shape, augmented_y_train.shape\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_s = np.concatenate((X_train_s, augmented_X_train), axis=0)\ny_train_s = np.concatenate((y_train_s, augmented_y_train), axis=0)\nX_train_s.shape, y_train_s.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''X_train_s = np.concatenate((X_train_s, X_train_s, X_train_s), axis=0)\ny_train_s = np.concatenate((y_train_s, y_train_s, y_train_s), axis=0)\nX_train_s.shape, y_train_s.shape'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test_s1 = np.concatenate((X_test_s, X_test_s, X_test_s), axis=0)\ny_test_s1 = np.concatenate((y_test_s, y_test_s, y_test_s), axis=0)\nX_test_s1.shape, y_test_s1.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_s.shape, y_train_s.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"augmented_X_train.shape, augmented_y_train.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"random_indices = np.random.choice(2430, 2003, replace=False)\n\nX_test_s1 = X_test_s1[random_indices]\ny_test_s1 = y_test_s1[random_indices]\n\nX_test_s1.shape, y_test_s1.shape, X_test_s.shape, y_test_s.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#X_train.shape, y_train.shape, X_test.shape, y_test.shape, \nX_train_s.shape,X_test_s.shape, y_train_s.shape,y_test_s.shape, X_test_s1.shape, y_test_s1.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(X_train_h.shape, y_train_h.shape, X_test_h.shape, y_test_h.shape,\n#X_train.shape, y_train.shape, X_test.shape, y_test.shape,\nX_train_s.shape,X_test_s.shape, X_test_s1.shape, y_train_s.shape,y_test_s.shape, y_test_s1.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Multi-branch fusion attention (MFA) module**","metadata":{}},{"cell_type":"code","source":"#### Multi-branch fusion attention (MFA) module #####\n\nclass DeeperGlobalLocalAttentionLayer1(layers.Layer):\n    def __init__(self, units, activation='sigmoid', dropout_rate=0.2, use_scale=True, axis=-1, **kwargs):\n        super(DeeperGlobalLocalAttentionLayer1, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activation\n        self.dropout_rate = dropout_rate\n        self.use_scale = use_scale\n        self.axis = axis\n\n    def build(self, input_shape):\n        _, _, _, channels = input_shape\n        self.global_conv1 = layers.Conv2D(filters=self.units, kernel_size=(1, 1), activation=self.activation)\n        self.global_avg_pooling1 = layers.GlobalAveragePooling2D()\n        \n        self.global_conv2 = layers.Conv2D(filters=self.units, kernel_size=(1, 1), activation=self.activation)\n        self.global_avg_pooling2 = layers.GlobalMaxPooling2D()\n        \n        self.global_conv3 = layers.Conv2D(filters=self.units, kernel_size=(1, 1), activation=self.activation)\n        self.global_avg_pooling3 = layers.GlobalAveragePooling2D()\n        \n        self.global_conv4 = layers.Conv2D(filters=self.units, kernel_size=(1, 1), activation=self.activation)\n        self.global_avg_pooling4 = layers.GlobalMaxPooling2D()\n        \n        self.concat1 = layers.Add()\n        self.concat2 = layers.Add()\n        self.concat3 = layers.Add()\n        self.concat4 = layers.Add()\n        self.concat5 = layers.Concatenate(axis=-1)\n        \n        self.global_attention = layers.Dense(units=self.units, activation=self.activation)\n        \n        self.local_conv1 = layers.Conv2D(filters=self.units, kernel_size=(1, 1), activation=self.activation)\n        self.local_conv2 = layers.Conv2D(filters=self.units, kernel_size=(1, 1), activation=self.activation)\n        self.concat6 = layers.Add()\n        \n        if self.use_scale:\n            self.global_scale = self.add_weight(shape=(1, 1, 1, 1), initializer='ones', trainable=True, name='global_scale')\n            self.local_scale = self.add_weight(shape=(1, 1, 1, self.units), initializer='ones', trainable=True, name='local_scale')\n        \n        super(DeeperGlobalLocalAttentionLayer1, self).build(input_shape)\n\n    def call(self, inputs, training=None):\n        ##### Hierarchical Information Fusion Attention(HIFA) ######\n        \n        global_attention1 = self.global_conv1(inputs)\n        global_avg1 = self.global_avg_pooling1(global_attention1)\n        \n        global_attention2 = self.global_conv2(global_attention1)\n        global_avg2 = self.global_avg_pooling2(global_attention2)\n        \n        global_concat1 = self.concat1([global_avg1, global_avg2])\n        global_attention_concat1 = self.concat2([global_attention1, global_attention2])\n        \n        global_attention3 = self.global_conv3(global_attention_concat1)\n        global_avg3 = self.global_avg_pooling3(global_attention3)\n        \n        global_attention4 = self.global_conv4(global_attention3)\n        global_avg4 = self.global_avg_pooling4(global_attention4)\n        \n        global_concat2 = self.concat3([global_avg3, global_avg4])\n        global_attention_concat2 = self.concat4([global_attention3, global_attention4])\n        \n        global_avg_concat = self.concat5([global_concat1, global_concat2])\n        \n        global_attention = self.global_attention(global_avg_concat)\n        global_attention = tf.expand_dims(tf.expand_dims(global_attention, 1), 1)\n\n        ##### Channel-wise Local Information Attention (CLIA) ######\n        \n        local_attention1 = self.local_conv1(inputs)\n        local_attention1 = tf.reduce_mean(local_attention1, axis=[1, 2], keepdims=True)  # Reduce spatial dimensions\n        local_attention2 = self.local_conv2(local_attention1)\n        local_attention2 = tf.reduce_mean(local_attention2, axis=[1, 2], keepdims=True)  # Reduce spatial dimensions\n        \n        local_attention = self.concat6([local_attention1, local_attention2])\n        \n        # Scale Global and Local Attention\n        if self.use_scale:\n            global_attention *= self.global_scale\n            local_attention *= self.local_scale\n\n        # Combine Global and Local Attention\n        attention = tf.sigmoid(global_attention + local_attention)\n        return attention\n\n    def get_config(self):\n        config = super(DeeperGlobalLocalAttentionLayer1, self).get_config()\n        config.update({'units': self.units, 'activation': self.activation, 'dropout_rate': self.dropout_rate,\n                       'use_scale': self.use_scale})\n        return config\n\nclass DeeperAttentionLayer1(layers.Layer):\n    def __init__(self, units=64, use_scale=True, **kwargs):\n        super(DeeperAttentionLayer1, self).__init__(**kwargs)\n        self.units = units\n        self.use_scale = use_scale\n\n    def build(self, input_shape):\n        _, H, W, C = input_shape\n        self.alpha = self.add_weight(shape=(1, 1, 1, C), initializer='ones', trainable=True, name='alpha')\n        self.deeper_global_local_attention = DeeperGlobalLocalAttentionLayer1(units=self.units, activation='sigmoid', \n                                                                              dropout_rate=0.2,  # You can adjust the dropout rate\n                                                                              use_scale=self.use_scale)\n        super(DeeperAttentionLayer1, self).build(input_shape)\n\n    def call(self, inputs, training=None):\n        attention = self.deeper_global_local_attention(inputs, training=training)\n        attention_feature = inputs * attention * self.alpha\n        return attention_feature\n\n    def get_config(self):\n        config = super(DeeperAttentionLayer1, self).get_config()\n        config.update({'units': self.units, 'use_scale': self.use_scale})\n        return config\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Multimodal information fusion attention (MIFA)**","metadata":{}},{"cell_type":"code","source":"########## Multimodal information fusion attention (MIFA) ###############\n\n\n\nclass GlobalMinPooling2D(layers.Layer):\n    def __init__(self, **kwargs):\n        super(GlobalMinPooling2D, self).__init__(**kwargs)\n\n    def call(self, inputs):\n        return tf.reduce_min(inputs, axis=[1, 2])\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], input_shape[-1])\n\n    def get_config(self):\n        config = super(GlobalMinPooling2D, self).get_config()\n        return config\n\n\nclass DeeperGlobalLocalAttentionLayer(layers.Layer):\n    def __init__(self, units, activation='sigmoid', dropout_rate=0.2, use_scale=True, axis=-1, **kwargs):\n        super(DeeperGlobalLocalAttentionLayer, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activation\n        self.dropout_rate = dropout_rate\n        self.use_scale = use_scale\n        self.axis = axis\n\n    def build(self, input_shapes):\n        input_shape1, input_shape2 = input_shapes\n        _, _, _, channels1 = input_shape1\n        _, _, _, channels2 = input_shape2\n        \n        self.global_min_pooling1 = GlobalMinPooling2D()\n        self.global_avg_pooling1 = layers.GlobalAveragePooling2D()\n        self.global_max_pooling1 = layers.GlobalMaxPooling2D()\n        \n        self.global_attention = layers.Dense(units=self.units, activation=self.activation)\n        \n        self.global_min_pooling2 = GlobalMinPooling2D()\n        self.global_avg_pooling2 = layers.GlobalAveragePooling2D()\n        self.global_max_pooling2 = layers.GlobalMaxPooling2D()\n        \n        #self.global_attention2 = layers.Dense(units=self.units, activation=self.activation)\n        \n        \n        self.concat = layers.Add()\n        #self.global_attention3 = layers.Dense(units=self.units, activation=self.activation)\n        \n        self.local_conv1 = layers.Conv2D(filters=self.units, kernel_size=(1, 1), activation=self.activation)\n        self.local_conv2 = layers.Conv2D(filters=self.units, kernel_size=(1, 1), activation=self.activation)\n        \n        \n        \n        self.concat2 = layers.Add()\n        #self.local_conv5 = layers.Conv2D(filters=self.units, kernel_size=(1, 1), activation=self.activation)\n        \n        if self.use_scale:\n            self.global_scale = self.add_weight(shape=(1, 1, 1, 1), initializer='ones', trainable=True, name='global_scale')\n            self.local_scale = self.add_weight(shape=(1, 1, 1, self.units), initializer='ones', trainable=True, name='local_scale')\n        \n        super(DeeperGlobalLocalAttentionLayer, self).build(input_shapes)\n\n    def call(self, inputs, training=None):\n        inputs1, inputs2 = inputs\n\n        #########  Multimodal Global Information Fusion Attention (MGIFA) #########\n        global_min1 = self.global_min_pooling1(inputs1)\n        global_avg1 = self.global_avg_pooling1(inputs1)\n        global_max1 = self.global_max_pooling1(inputs1)\n\n        global_min2 = self.global_min_pooling2(inputs2)\n        global_avg2 = self.global_avg_pooling2(inputs2)\n        global_max2 = self.global_max_pooling2(inputs2)\n\n        concat_min = self.concat([global_min1, global_min2])\n        concat_avg = self.concat([global_avg1, global_avg2])\n        concat_max = self.concat([global_max1, global_max2])\n        \n        concat_min = self.global_attention(concat_min)\n        concat_avg = self.global_attention(concat_avg)\n        concat_max = self.global_attention(concat_max)\n        \n        concat_global_attention = self.concat([concat_min, concat_avg, concat_max])\n        \n        #global_attention = self.global_attention3(concat_global_attention)\n        \n        global_attention = tf.expand_dims(tf.expand_dims(concat_global_attention, 1), 1)\n\n        #########  Multimodal Local Information Fusion Attention (MLIFA) #########\n        \n        local_conv1 = self.local_conv1(inputs1)\n        local_min1 = tf.reduce_min(local_conv1, axis=[1, 2], keepdims=True)  # Reduce spatial dimensions\n        local_avg1 = tf.reduce_mean(local_conv1, axis=[1, 2], keepdims=True)  # Reduce spatial dimensions\n        local_max1 = tf.reduce_max(local_conv1, axis=[1, 2], keepdims=True)  # Reduce spatial dimensions\n        \n        local_conv2 = self.local_conv2(inputs2)\n        local_min2 = tf.reduce_min(local_conv2, axis=[1, 2], keepdims=True)  # Reduce spatial dimensions\n        local_avg2 = tf.reduce_mean(local_conv2, axis=[1, 2], keepdims=True)  # Reduce spatial dimensions\n        local_max2 = tf.reduce_max(local_conv2, axis=[1, 2], keepdims=True)  # Reduce spatial dimensions\n        \n        local_concat_min = self.concat2([local_min1, local_min2])\n        local_concat_avg = self.concat2([local_avg1, local_avg2])\n        local_concat_max = self.concat2([local_max1, local_max2])\n\n        local_attention = self.concat2([local_concat_min, local_concat_avg, local_concat_max])\n        \n        \n        # Scale Global and Local Attention\n        if self.use_scale:\n            global_attention *= self.global_scale\n            local_attention *= self.local_scale\n\n        # Combine Global and Local Attention\n        attention = tf.sigmoid(global_attention + local_attention)\n        return attention\n\n    def get_config(self):\n        config = super(DeeperGlobalLocalAttentionLayer, self).get_config()\n        config.update({'units': self.units, 'activation': self.activation, 'dropout_rate': self.dropout_rate,\n                       'use_scale': self.use_scale})\n        return config\n\nclass DeeperAttentionLayer(layers.Layer):\n    def __init__(self, units=64, use_scale=True,axis=-1, **kwargs):\n        super(DeeperAttentionLayer, self).__init__(**kwargs)\n        self.units = units\n        self.use_scale = use_scale\n        self.axis = axis \n\n    def build(self, input_shapes):\n        input_shape1, input_shape2 = input_shapes\n        _, H, W, C1 = input_shape1\n        _, H, W, C2 = input_shape2\n        \n        self.alpha1 = self.add_weight(shape=(1, 1, 1, C1), initializer='ones', trainable=True, name='alpha1')\n        self.alpha2 = self.add_weight(shape=(1, 1, 1, C2), initializer='ones', trainable=True, name='alpha2')\n        \n        self.deeper_global_local_attention = DeeperGlobalLocalAttentionLayer(units=self.units, activation='sigmoid', \n                                                                              dropout_rate=0.2,  # You can adjust the dropout rate\n                                                                              use_scale=self.use_scale)\n        #self.concat3 = layers.Add()\n        #self.concat4 = layers.Add()\n        \n        super(DeeperAttentionLayer, self).build(input_shapes)\n\n    def call(self, inputs, training=None):\n        inputs1, inputs2 = inputs\n        attention = self.deeper_global_local_attention([inputs1, inputs2], training=training)\n        \n        #inputs_concat = self.concat3([inputs1, inputs2])\n        #alpha_concat = self.concat4([self.alpha1, self.alpha2])\n        \n        attention_feature1 = inputs1 * attention * self.alpha1\n        attention_feature2 = inputs2 * attention * self.alpha2\n        \n        return attention_feature1, attention_feature2\n\n    def get_config(self):\n        config = super(DeeperAttentionLayer, self).get_config()\n        config.update({'units': self.units, 'use_scale': self.use_scale})\n        return config\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### RRA block ########\n\ndef RGSA(x, filters, strides=(1, 1), use_projection=False):\n    shortcut = x\n\n    # Define the first convolutional layer of the block\n    \n    x = Conv2D(filters=filters, kernel_size=(3, 3), strides=strides, padding='same', \n               #activation = 'relu'\n\n              )(x)\n    x = DeeperAttentionLayer1(units=filters, use_scale=True)(x)\n    x = BatchNormalization()(x)\n    x = tf.keras.layers.Activation('relu')(x)\n\n    # Define the second convolutional layer of the block\n    \n    x = Conv2D(filters=filters, kernel_size=(3, 3), padding='same')(x)\n    x = DeeperAttentionLayer1(units=filters, use_scale=True)(x)\n    \n    x = BatchNormalization()(x)\n\n    # If the stride is not (1, 1), the dimensions need to be adjusted\n    if strides != (1, 1) or use_projection:\n        \n        shortcut = Conv2D(filters=filters, kernel_size=(1, 1), strides=strides, padding='same')(shortcut)\n        shortcut = BatchNormalization()(shortcut)\n\n    # Add the shortcut (identity connection)\n    \n    x = tf.keras.layers.add([x, shortcut])\n    \n    x = tf.keras.layers.Activation('relu')(x)\n    return x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def residual_GLC_branch1(inputs1, inputs2):\n    \n    x1 = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), padding='same')(inputs1)\n    x1 = DeeperAttentionLayer1(units=64, use_scale=True)(x1) ## MFA ####\n    x1 = BatchNormalization()(x1)\n    x1 = tf.keras.layers.Activation('relu')(x1)\n    x1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x1)\n    \n    x2 = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), padding='same')(inputs2)\n    x2 = DeeperAttentionLayer1(units=64, use_scale=True)(x2) ## MFA ####\n    x2 = BatchNormalization()(x2)\n    x2 = tf.keras.layers.Activation('relu')(x2)\n    x2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x2)\n    \n\n    x1 = RGSA(x1, filters=64)\n    x1 = tf.keras.layers.Dropout(0.25)(x1, training = True)  ## MCD ####\n    x1 = DeeperAttentionLayer1(units=64, use_scale=True)(x1) ## MFA ####\n\n    x2 = RGSA(x2, filters=64)\n    x2 = tf.keras.layers.Dropout(0.25)(x2, training = True)  ## MCD ####\n    x2 = DeeperAttentionLayer1(units=64, use_scale=True)(x2)\n    \n    x1, x2 = DeeperAttentionLayer(units=64, use_scale=True)([x1, x2])  ## MIFA ####\n    \n    x1 = RGSA(x1, filters=64)\n    x1 = tf.keras.layers.Dropout(0.25)(x1, training = True)  ## MCD ####\n    x1 = DeeperAttentionLayer1(units=64, use_scale=True)(x1) ## MFA ####\n    \n    x2 = RGSA(x2, filters=64)\n    x2 = tf.keras.layers.Dropout(0.25)(x2, training = True)  ## MCD ####\n    x2 = DeeperAttentionLayer1(units=64, use_scale=True)(x2)\n\n    x1, x2 = DeeperAttentionLayer(units=64, use_scale=True)([x1, x2])  ## MIFA ####\n    \n    x1 = RGSA(x1, filters=128, strides=(2, 2), use_projection=True)\n    x1 = tf.keras.layers.Dropout(0.25)(x1, training = True)  ## MCD ####\n    x1 = DeeperAttentionLayer1(units=128, use_scale=True)(x1) ## MFA ####\n\n    x2 = RGSA(x2, filters=128, strides=(2, 2), use_projection=True)\n    x2 = tf.keras.layers.Dropout(0.25)(x2, training = True)  ## MCD ####\n    x2 = DeeperAttentionLayer1(units=128, use_scale=True)(x2)\n\n    x1, x2 = DeeperAttentionLayer(units=128, use_scale=True)([x1, x2])  ## MIFA ####\n    \n    x1 = RGSA(x1, filters=128)\n    x1 = tf.keras.layers.Dropout(0.25)(x1, training = True)  ## MCD ####\n    x1 = DeeperAttentionLayer1(units=128, use_scale=True)(x1)\n  \n    x2 = RGSA(x2, filters=128)\n    x2 = tf.keras.layers.Dropout(0.25)(x2, training = True)  ## MCD ####\n    x2 = DeeperAttentionLayer1(units=128, use_scale=True)(x2)\n\n    x1, x2 = DeeperAttentionLayer(units=128, use_scale=True)([x1, x2])  ## MIFA ####\n    \n    x1 = RGSA(x1, filters=256, strides=(2, 2), use_projection=True)\n    x1 = tf.keras.layers.Dropout(0.25)(x1, training = True)  ## MCD ####\n    x1 = DeeperAttentionLayer1(units=256, use_scale=True)(x1)\n    \n    x2 = RGSA(x2, filters=256, strides=(2, 2), use_projection=True)\n    x2 = tf.keras.layers.Dropout(0.25)(x2, training = True)  ## MCD ####\n    x2 = DeeperAttentionLayer1(units=256, use_scale=True)(x2)\n\n    x1, x2 = DeeperAttentionLayer(units=256, use_scale=True)([x1, x2])  ## MIFA ####\n    \n    \n    x1 = RGSA(x1, filters=256)\n    x1 = tf.keras.layers.Dropout(0.25)(x1, training = True)  ## MCD ####\n    x1 = DeeperAttentionLayer1(units=256, use_scale=True)(x1)\n    \n    x2 = RGSA(x2, filters=256)\n    x2 = tf.keras.layers.Dropout(0.25)(x2, training = True)  ## MCD ####\n    x2 = DeeperAttentionLayer1(units=256, use_scale=True)(x2)\n    \n    x1, x2 = DeeperAttentionLayer(units=256, use_scale=True)([x1, x2])  ## MIFA ####\n\n    x1 = RGSA(x1, filters=512, strides=(2, 2), use_projection=True)\n    x1 = DeeperAttentionLayer1(units=512, use_scale=True)(x1)\n    \n    x2 = RGSA(x2, filters=512, strides=(2, 2), use_projection=True)\n    x2 = DeeperAttentionLayer1(units=512, use_scale=True)(x2)\n\n    x1, x2 = DeeperAttentionLayer(units=512, use_scale=True)([x1, x2])  ## MIFA ####\n    \n    x1 = RGSA(x1, filters=512)\n    x2 = RGSA(x2, filters=512)\n    x1, x2 = DeeperAttentionLayer(units=512, use_scale=True)([x1, x2])\n    \n    return x1, x2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#def build_resnet18(input_shape=(128, 128, 3), num_classes=2):\ninput_shape=(128, 128, 3)\ninputs1 = Input(shape=input_shape)\ninputs2 = Input(shape=input_shape)\n\n\n\n#input_data = Input(shape=input_shape, name='input_data')\n# Initial convolutional layer\n\nx1, x2 = residual_GLC_branch1(inputs1, inputs2)\n#print('x:',x.shape)\n\ncon = tf.keras.layers.Concatenate(axis=-1)([x1, x2])\n\ncon = tf.keras.layers.Dropout(0.25)(con, training = True)  ## MCD ####\n\nx = GlobalAveragePooling2D()(con)\nprint('GlobalAveragePooling2D x:',x.shape)\n\noutputs1 = Dense(5, activation='softmax')(x)\noutputs2 = Dense(7, activation='softmax')(x)\n\n# Create the model\nmodel = Model([inputs1, inputs2], [outputs1, outputs2])\n#return model\nprint(model.summary())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\ninitial_gamma = 0.5\n\noptimizer = Adam(learning_rate=0.001)\n# Compile the model with the custom optimizer\nmodel.compile(optimizer=optimizer,\n              loss=['categorical_crossentropy', 'categorical_crossentropy'],\n              loss_weights=[initial_gamma, (1 -  initial_gamma)],\n              metrics=['accuracy', 'accuracy'])\n\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\ndef checkpoint_callback():\n\n    checkpoint_filepath = 'best1_model_cer_skin_lung.keras'\n\n    model_checkpoint_callback= ModelCheckpoint(filepath=checkpoint_filepath,\n                           save_weights_only=False,\n                           #frequency='epoch',\n                           monitor='val_loss',\n                           save_best_only=True,\n                            mode='min',\n                           verbose=0)\n\n    return model_checkpoint_callback\n\ndef early_stopping(patience):\n    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, verbose=1)\n    return es_callback\n\n\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=5, min_lr=0.00001)\n\ncheckpoint_callback = checkpoint_callback()\n\nearly_stopping = early_stopping(patience=100)\ncallbacks = [checkpoint_callback, early_stopping, reduce_lr]\n            \n\n# Fit the model with callbacks\nhistory = model.fit([X_train_s, X_train_h], [y_train_s, y_train_h],\n                    epochs=200,\n                    validation_split=0.2, verbose=1,\n                    shuffle=True,\n                    callbacks=callbacks) # UpdateGammaCallback\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.evaluate([X_test_s, X_test_h1], [y_test_s, y_test_h1])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nmodel.evaluate([X_test_s1, X_test_h], [y_test_s1, y_test_h])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = model.predict([X_test_s1, X_test_h]) \n\ny_pred_binary1 = y_pred[0] >= 0.5\ny_pred_binary_pgd_test1 = np.array(y_pred_binary1, dtype='int32')\n\nprint('y_pred_binary_pgd_test1:', y_pred_binary_pgd_test1.shape)\n\ny_pred_binary2 = y_pred[1] >= 0.5\ny_pred_binary_pgd_test2 = np.array(y_pred_binary2, dtype='int32')\n\nprint('y_pred_binary_pgd_test2:', y_pred_binary_pgd_test2.shape)\n\n#y_test_s, y_test_h\n# Calculate evaluation metrics for the current epsilon\ny_test_categorical1 = y_test_s1\ny_test_categorical2 = y_test_h\n\n## Task 1:\nprint('skin cancer classification:')\naccuracy = accuracy_score(y_pred_binary_pgd_test1, y_test_categorical1) * 100\nprecision = precision_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\n#auc = roc_auc_score(y_pred, y_train_categorical, multi_class='ovr') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)\n\n## Task 2:\nprint('Cervical cancer classification:')\naccuracy = accuracy_score(y_pred_binary_pgd_test2, y_test_categorical2) * 100\nprecision = precision_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit([X_train_s, X_train_h], [y_train_s, y_train_h],\n                    epochs=100,\n                    validation_split=0.2, verbose=1,\n                    shuffle=True,\n                   callbacks=callbacks)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.evaluate([X_test_s, X_test_h1], [y_test_s, y_test_h1])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\nmodel1 = load_model('/kaggle/working/best1_model_cer_skin_lung.keras', custom_objects={'DeeperAttentionLayer1': DeeperAttentionLayer1,\n                                                                         'DeeperAttentionLayer': DeeperAttentionLayer\n                                                                  })\nmodel1.evaluate([X_test_s, X_test_h1], [y_test_s, y_test_h1])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.evaluate([X_test_s1, X_test_h], [y_test_s1, y_test_h])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = model.predict([X_test_s1, X_test_h]) \n\ny_pred_binary1 = y_pred[0] >= 0.5\ny_pred_binary_pgd_test1 = np.array(y_pred_binary1, dtype='int32')\n\nprint('y_pred_binary_pgd_test1:', y_pred_binary_pgd_test1.shape)\n\ny_pred_binary2 = y_pred[1] >= 0.5\ny_pred_binary_pgd_test2 = np.array(y_pred_binary2, dtype='int32')\n\nprint('y_pred_binary_pgd_test2:', y_pred_binary_pgd_test2.shape)\n\n#y_test_s, y_test_h\n# Calculate evaluation metrics for the current epsilon\ny_test_categorical1 = y_test_s1\ny_test_categorical2 = y_test_h\n\n## Task 1:\nprint('skin cancer classification:')\naccuracy = accuracy_score(y_pred_binary_pgd_test1, y_test_categorical1) * 100\nprecision = precision_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\n#auc = roc_auc_score(y_pred, y_train_categorical, multi_class='ovr') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)\n\n## Task 2:\nprint('Cervical cancer classification:')\naccuracy = accuracy_score(y_pred_binary_pgd_test2, y_test_categorical2) * 100\nprecision = precision_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = model.predict([X_test_s, X_test_h1]) \n\ny_pred_binary1 = y_pred[0] >= 0.5\ny_pred_binary_pgd_test1 = np.array(y_pred_binary1, dtype='int32')\n\nprint('y_pred_binary_pgd_test1:', y_pred_binary_pgd_test1.shape)\n\ny_pred_binary2 = y_pred[1] >= 0.5\ny_pred_binary_pgd_test2 = np.array(y_pred_binary2, dtype='int32')\n\nprint('y_pred_binary_pgd_test2:', y_pred_binary_pgd_test2.shape)\n\n#y_test_s, y_test_h\n# Calculate evaluation metrics for the current epsilon\ny_test_categorical1 = y_test_s\ny_test_categorical2 = y_test_h1\n\n## Task 1:\nprint('skin cancer classification:')\naccuracy = accuracy_score(y_pred_binary_pgd_test1, y_test_categorical1) * 100\nprecision = precision_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test1, y_test_categorical1, average='macro') * 100\n#auc = roc_auc_score(y_pred, y_train_categorical, multi_class='ovr') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)\n\n## Task 2:\nprint('Cervical cancer classification:')\naccuracy = accuracy_score(y_pred_binary_pgd_test2, y_test_categorical2) * 100\nprecision = precision_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nrecall = recall_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nf1 = f1_score(y_pred_binary_pgd_test2, y_test_categorical2, average='macro') * 100\nprint('accuracy:', accuracy)\nprint('precision:', precision)\nprint('recall:', recall)\nprint('f1:', f1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('best_model_ever.keras')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}